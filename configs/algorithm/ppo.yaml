# configs/algorithms/ppo.yaml
name: ppo

policy: MlpPolicy

learning_rate: 3e-4
n_steps: 2048
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5

total_timesteps: 1_000_000
