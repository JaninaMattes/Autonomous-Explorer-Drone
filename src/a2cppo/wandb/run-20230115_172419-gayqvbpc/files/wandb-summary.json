{"train/timesteps": 3756, "train/mean policy loss": -0.5179169774055481, "train/mean value loss": 0.07037799805402756, "train/mean episode returns": -192.714908, "train/std episode returns": 128.116132, "train/mean episode runtime": 0.04974, "train/mean episode length": 200.0, "_timestamp": 1673801037.537387, "_runtime": 1177.7085139751434, "_step": 1556, "_wandb": {"runtime": 1177}}