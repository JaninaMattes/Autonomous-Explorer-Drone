INFO:root:Training model...
INFO:root:Collecting batch trajectories...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:
INFO:root:------------ Episode: 2200 --------------
INFO:root:Mean return:          -1224.634815
INFO:root:Mean policy loss:     -0.0002530000056140125
INFO:root:Mean value loss:      1.1068580150604248
INFO:root:--------------------------------------------
INFO:root:
Traceback (most recent call last):
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 1079, in <module>
    train(env,
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 921, in train
    agent.learn()
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 680, in learn
    running_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward
TypeError: can't multiply sequence by non-int of type 'float'