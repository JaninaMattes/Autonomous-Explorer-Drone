INFO:root:Training model...
INFO:root:Collecting batch trajectories...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:Updating network parameter...
INFO:root:
INFO:root:------------ Episode: 2200 --------------
INFO:root:Mean return:          -1224.634815
INFO:root:Mean policy loss:     -0.0002530000056140125
INFO:root:Mean value loss:      1.1068580150604248
INFO:root:--------------------------------------------
INFO:root:
Traceback (most recent call last):
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 1079, in <module>
    train(env,
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 921, in train
    agent.learn()
  File "/Volumes/Work Disk Janina Mattes/DEV/University/ASP/ml-explorer-drone/PPO/ppo_torch/ppo_continuous.py", line 681, in learn
    if running_reward > self.env.spec.reward_threshold:
TypeError: '>' not supported between instances of 'float' and 'NoneType'