{"train/timesteps": 2002000, "train/mean policy loss": -0.004548999946564436, "train/mean value loss": 0.0327799990773201, "train/mean episode returns": -209.197508, "train/min episode returns": -355.633833, "train/max episode returns": -118.66049, "train/std episode returns": 85.994998, "train/mean episode runtime": 0.038772, "train/mean episode length": 200.0, "train/episodes": 909, "_timestamp": 1673945746.059105, "_runtime": 480.6630129814148, "_step": 909, "_wandb": {"runtime": 478}}