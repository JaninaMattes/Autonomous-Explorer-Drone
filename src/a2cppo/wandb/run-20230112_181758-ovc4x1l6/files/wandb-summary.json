{"train/timesteps": 2200, "train/mean policy loss": -0.0002995082759298384, "train/mean value loss": 151817.296875, "train/mean episode returns": -1224.6348146315077, "train/std episode returns": 293.073728357983, "train/mean episode runtime": 0.038459821180863815, "train/mean episode length": 200.0, "_timestamp": 1673543882.180754, "_runtime": 3.430137872695923, "_step": 0, "_wandb": {"runtime": 3}}