{"train/timesteps": 2200, "train/mean policy loss": -0.0006329999887384474, "train/mean value loss": 20056.53125, "train/mean episode returns": -1224.634815, "train/min episode returns": -1633.46679, "train/max episode returns": -739.713681, "train/std episode returns": 293.073728, "train/mean episode runtime": 0.185471, "train/mean episode length": 200.0, "train/episodes": 0, "_timestamp": 1673980439.3592288, "_runtime": 7.393011808395386, "_step": 0, "_wandb": {"runtime": 12}}