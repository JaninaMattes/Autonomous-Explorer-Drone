{"train/timesteps": 3000800, "train/mean policy loss": -0.002824000082910061, "train/mean value loss": 0.30003100633621216, "train/mean episode returns": -219.503718, "train/std episode returns": 203.089548, "train/mean episode runtime": 0.03623, "train/mean episode length": 200.0, "_timestamp": 1673605175.372891, "_runtime": 618.5096719264984, "_step": 1363}