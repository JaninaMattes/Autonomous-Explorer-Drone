{"train/timesteps": 2200, "train/mean policy loss": -0.0002995082759298384, "train/mean value loss": 151817.296875, "train/mean episode returns": -1224.6348146315077, "train/std episode returns": 293.073728357983, "train/mean episode runtime": 0.041862292723222214, "train/mean episode length": 200.0, "_timestamp": 1673541640.6756449, "_runtime": 4.011002779006958, "_step": 0, "_wandb": {"runtime": 2}}