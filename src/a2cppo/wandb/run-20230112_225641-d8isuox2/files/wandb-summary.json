{"train/timesteps": 1001000, "train/mean policy loss": -0.0007050000131130219, "train/mean value loss": 6646.37646484375, "train/mean episode returns": -803.910809, "train/std episode returns": 83.079681, "train/mean episode runtime": 0.035586, "train/mean episode length": 200.0, "_timestamp": 1673560807.934498, "_runtime": 206.860915184021, "_step": 454, "_wandb": {"runtime": 206}}