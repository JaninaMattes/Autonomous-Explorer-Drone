{"train/timesteps": 2948000, "train/mean policy loss": -0.0019809999503195286, "train/mean value loss": 0.8351029753684998, "train/mean episode returns": -1569.243846, "train/std episode returns": 57.115128, "train/mean episode runtime": 0.037171, "train/mean episode length": 200.0, "_timestamp": 1673782815.939275, "_runtime": 703.154736995697, "_step": 1339, "_wandb": {"runtime": 702}}