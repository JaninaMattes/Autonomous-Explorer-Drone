diff --git a/.gitignore b/.gitignore
index 2d5f4324..b9ee61da 100644
--- a/.gitignore
+++ b/.gitignore
@@ -37,7 +37,7 @@ sysinfo.txt
 
 # Monitoring
 */wandb/*
-ppo_impl/ppo_torch/wandb/*
+PPO/ppo_torch/wandb/
 
 # Checkpoints
 # IPython notebook checkpoints
diff --git a/PPO/ppo_torch/ppo_continuous.py b/PPO/ppo_torch/ppo_continuous.py
index 617da7b1..8eb952cd 100644
--- a/PPO/ppo_torch/ppo_continuous.py
+++ b/PPO/ppo_torch/ppo_continuous.py
@@ -248,7 +248,6 @@ class PPO_PolicyGradient:
                 advantages.insert(0, prev_advantage) # reverse it again
                 # store current value as V(s_t+1)
                 last_value = values[i]
-        advantages = np.array(advantages)
         if normalized:
             advantages = self.normalize_adv(advantages)
         return torch.tensor(np.array(advantages), dtype=torch.float), torch.tensor(np.array(returns), dtype=torch.float)
