{"train/timesteps": 169000, "train/mean policy loss": 6.010714054107666, "train/mean value loss": 0.06355074793100357, "train/mean episode length": 200.0, "train/mean episode returns": -1218.4063692031339, "train/std episode returns": 206.31681579398068, "_timestamp": 1673358914.532018, "_runtime": 37.59141683578491, "_step": 64, "_wandb": {"runtime": 37}}