{"train/timesteps": 2200, "train/mean policy loss": -0.0006329999887384474, "train/mean value loss": 20056.53125, "train/mean episode returns": -1224.634815, "train/min episode returns": -1633.46679, "train/max episode returns": -739.713681, "train/std episode returns": 293.073728, "train/mean episode runtime": 0.201018, "train/mean episode length": 200.0, "train/episodes": 0, "_timestamp": 1673980391.179084, "_runtime": 7.848692178726196, "_step": 0, "_wandb": {"runtime": 7}}