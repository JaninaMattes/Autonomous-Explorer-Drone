{"train/timesteps": 174232, "train/mean policy loss": -0.19157899916172028, "train/mean value loss": 0.006027999799698591, "train/mean episode returns": -73.313673, "train/min episode returns": -82.412983, "train/max episode returns": -70.141265, "train/std episode returns": 2.553751, "train/mean episode runtime": 0.01859, "train/mean episode length": 72.344828, "train/episodes": 82, "_timestamp": 1674147411.577253, "_runtime": 84.87170100212097, "_step": 82, "_wandb": {"runtime": 84}}