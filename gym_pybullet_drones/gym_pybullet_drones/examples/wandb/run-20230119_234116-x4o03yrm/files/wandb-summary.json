{"train/timesteps": 53248, "train/mean policy loss": -0.08823499828577042, "train/mean value loss": 0.9948319792747498, "train/mean episode returns": -0.888681, "train/min episode returns": -0.888856, "train/max episode returns": -0.888505, "train/std episode returns": 5.1e-05, "train/mean episode runtime": 0.000536, "train/mean episode length": 1.0, "train/episodes": 25, "_timestamp": 1674169803.2885602, "_runtime": 1726.2952091693878, "_step": 25, "_wandb": {"runtime": 1750}}