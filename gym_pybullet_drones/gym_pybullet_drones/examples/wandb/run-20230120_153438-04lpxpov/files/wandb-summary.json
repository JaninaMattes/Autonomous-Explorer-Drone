{"train/timesteps": 268288, "train/mean policy loss": -0.16968399286270142, "train/mean value loss": 0.9853410124778748, "train/mean episode returns": -0.787236, "train/min episode returns": -0.787298, "train/max episode returns": -0.787178, "train/std episode returns": 1.7e-05, "train/mean episode runtime": 0.000492, "train/mean episode length": 1.0, "train/episodes": 130, "_timestamp": 1674229931.842263, "_runtime": 4653.278865098953, "_step": 130, "_wandb": {"runtime": 4674}}