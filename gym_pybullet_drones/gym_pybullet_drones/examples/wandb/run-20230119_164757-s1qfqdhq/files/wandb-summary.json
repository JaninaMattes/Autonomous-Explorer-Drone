{"train/timesteps": 2079, "train/mean policy loss": -0.16658200323581696, "train/mean value loss": 0.9149770140647888, "train/mean episode returns": -213.566945, "train/min episode returns": -259.56452, "train/max episode returns": -165.077749, "train/std episode returns": 31.93451, "train/mean episode runtime": 0.077902, "train/mean episode length": 207.9, "train/episodes": 0, "_timestamp": 1674143281.686592, "_runtime": 3.692310094833374, "_step": 0, "_wandb": {"runtime": 2}}