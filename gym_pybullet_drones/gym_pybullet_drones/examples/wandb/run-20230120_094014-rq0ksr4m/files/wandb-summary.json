{"train/timesteps": 622592, "train/mean policy loss": -0.05828699842095375, "train/mean value loss": 0.9882760047912598, "train/mean episode returns": -0.78676, "train/min episode returns": -0.786828, "train/max episode returns": -0.786687, "train/std episode returns": 2.1e-05, "train/mean episode runtime": 0.000428, "train/mean episode length": 1.0, "train/episodes": 303, "_timestamp": 1674212877.335926, "_runtime": 8862.922579050064, "_step": 303, "_wandb": {"runtime": 8948}}