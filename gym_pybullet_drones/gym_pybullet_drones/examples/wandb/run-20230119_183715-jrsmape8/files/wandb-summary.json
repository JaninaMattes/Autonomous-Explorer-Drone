{"train/timesteps": 19290, "train/mean policy loss": -0.1674260050058365, "train/mean value loss": 0.09038499742746353, "train/mean episode returns": -160.410838, "train/min episode returns": -217.63054, "train/max episode returns": -133.460568, "train/std episode returns": 21.228609, "train/mean episode runtime": 0.04104, "train/mean episode length": 150.357143, "train/episodes": 8, "_timestamp": 1674149846.287456, "_runtime": 10.756386995315552, "_step": 8, "_wandb": {"runtime": 10}}