{"train/timesteps": 4096, "train/mean policy loss": 0.007792000193148851, "train/mean value loss": 0.9946789741516113, "train/mean episode returns": -0.888885, "train/min episode returns": -0.889035, "train/max episode returns": -0.888703, "train/std episode returns": 4.9e-05, "train/mean episode runtime": 0.000527, "train/mean episode length": 1.0, "train/episodes": 1, "_timestamp": 1674217633.560328, "_runtime": 64.01664996147156, "_step": 1, "_wandb": {"runtime": 63}}