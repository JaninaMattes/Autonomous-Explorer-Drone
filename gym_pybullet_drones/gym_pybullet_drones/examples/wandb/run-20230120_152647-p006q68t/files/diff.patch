diff --git a/README.md b/README.md
index ade3ad3f..0d52ed79 100644
--- a/README.md
+++ b/README.md
@@ -3,6 +3,7 @@
 This repository contains a UnityML drone environment and the PyBullet Drone environment as well as a custom PPO algorithm.
 
 ### Top level directory layout
+```
 .
 ├── docs                                # Documentation files, papers
 ├── imgs                                # Image files for README.md
@@ -14,6 +15,7 @@ This repository contains a UnityML drone environment and the PyBullet Drone envi
 ├── requirements.txt                    # requirements.txt for pybullet and ppo_v2
 ├── LICENSE
 └── README.md
+```
 
 ## 1. Unity [ml-explorer-drone environment]
 Unity Machine Learning Controlled Explorer Drone
@@ -47,10 +49,10 @@ Then register the custom PyBullet environemnts:
 
 [3] Training
 The default is the custom _PPO_v2_ algorithm with takeoff-aviary-v0 environment.
-Select a training from scratch with the flags:
+Select a training from scratch with optional flags (--algo, --train_steps, --env_id):
 
-- ```$ python learn.py --env_id "takeoff" --algo "ppo_v2"```
-- ```$ python learn.py --env_id "hover" --algo "ppo_v2"```
+- ```$ python learn.py --env_id "takeoff" --algo "ppo_v2" --train_steps 10_000```
+- ```$ python learn.py --env_id "hover" --algo "ppo_v2" --train_steps 10_000```
 
 
 ## 3. Custom implementation [PPO_V1, PPO_V2]
@@ -71,4 +73,7 @@ Run training with PPO
 
 [3] Hyperparameter Tuning
 Run training with PPO
-- ```python ppo_continuous.py --hyperparam True```
\ No newline at end of file
+- ```python ppo_continuous.py --hyperparam True```
+
+## 4. Logging
+All training results are logged under W&B and ```./log``` in the respective directory.
\ No newline at end of file
diff --git a/gym_pybullet_drones/gym_pybullet_drones/examples/learn.py b/gym_pybullet_drones/gym_pybullet_drones/examples/learn.py
index e2510e58..fc631819 100644
--- a/gym_pybullet_drones/gym_pybullet_drones/examples/learn.py
+++ b/gym_pybullet_drones/gym_pybullet_drones/examples/learn.py
@@ -20,6 +20,7 @@ import time
 import argparse
 import gym
 from gym_pybullet_drones.envs.single_agent_rl.HoverAviary import HoverAviary
+from gym_pybullet_drones.utils.enums import DroneModel, Physics
 import numpy as np
 from stable_baselines3 import A2C
 from stable_baselines3.a2c import MlpPolicy
@@ -36,12 +37,25 @@ from gym_pybullet_drones.utils.utils import sync, str2bool
 import gym_pybullet_drones.examples.ppo as ppo
 from gym_pybullet_drones.examples.ppo import PPOTrainer
 
+#######################################
+#######################################
+
+DEFAULT_VISION = False
 DEFAULT_ENV = 'takeoff' #"takeoff", "hover"
 DEFAULT_RLLIB = True
 DEFAULT_ALGO = 'ppo_v2'
+DEFAULT_DRONES = DroneModel("cf2x")
+DEFAULT_NUM_DRONES = 3
+DEFAULT_PHYSICS = Physics("pyb")
+
+DEFAULT_AGGREGATE = True
+DEFAULT_SIMULATION_FREQ_HZ = 240
+DEFAULT_CONTROL_FREQ_HZ = 48
+
 DEFAULT_GUI = True
 DEFAULT_USER_DEBUG_GUI = False
 DEFAULT_RECORD_VIDEO = True
+DEFAULT_PLOT = True
 DEFAULT_OUTPUT_FOLDER = 'results'
 DEFAULT_COLAB = False
 DEFAULT_SEED = 42
@@ -51,28 +65,41 @@ DEFAULT_TRAINING_STEPS = 100_000 # just for testing, too short otherwise
 #######################################
 
 
-def make_env(env_id, seed=42):
-    env = gym.make(env_id)
-    env.seed(seed)
-    env.action_space.seed(seed)
-    env.observation_space.seed(seed)
-    return env
 
 def run(env_id=DEFAULT_ENV, 
         rllib=DEFAULT_RLLIB, 
         algo=DEFAULT_ALGO,
         train_steps=DEFAULT_TRAINING_STEPS,
+        drone=DEFAULT_DRONES,
+        num_drones=DEFAULT_NUM_DRONES,
+        physics=DEFAULT_PHYSICS,
+        vision=DEFAULT_VISION,
+        aggregate=DEFAULT_AGGREGATE,
+        simulation_freq_hz=DEFAULT_SIMULATION_FREQ_HZ,
+        control_freq_hz=DEFAULT_CONTROL_FREQ_HZ,
         output_folder=DEFAULT_OUTPUT_FOLDER, 
         gui=DEFAULT_GUI,
-        plot=True, 
+        plot=DEFAULT_PLOT,
         colab=DEFAULT_COLAB, 
         record_video=DEFAULT_RECORD_VIDEO, 
         seed=DEFAULT_SEED):
     
     #############################################################
-    #### Check the environment's spaces ########################
+    #### Initialize spaces ########################
     #############################################################
 
+    H = .1
+    H_STEP = .05
+    R = .3
+    INIT_XYZS = np.array([[R*np.cos((i/6)*2*np.pi+np.pi/2), R*np.sin((i/6)*2*np.pi+np.pi/2)-R, H+i*H_STEP] for i in range(num_drones)])
+    INIT_RPYS = np.array([[0, 0,  i * (np.pi/2)/num_drones] for i in range(num_drones)])
+    AGGR_PHY_STEPS = int(simulation_freq_hz/control_freq_hz) if aggregate else 1
+
+
+    #############################################################
+    #### Check the environment's spaces ########################
+    #############################################################
+    
     if not env_id in ['takeoff', 'hover']: 
         print("[ERROR] 1D action space is only compatible with Takeoff and HoverAviary")
         exit()
@@ -142,13 +169,25 @@ def run(env_id=DEFAULT_ENV,
     ############################################################
 
     if env_id == 'takeoff':
-        env = TakeoffAviary(gui=gui,
+        env = TakeoffAviary(drone_model=drone,
+                            initial_xyzs=INIT_XYZS,
+                            initial_rpys=INIT_RPYS,
+                            freq=simulation_freq_hz,
+                            aggregate_phy_steps=AGGR_PHY_STEPS,
+                            gui=gui,
+                            physics=physics,
                             record=record_video
                             )
     elif env_id == 'hover':
-        env = HoverAviary(gui=gui,
+        env = HoverAviary(drone_model=drone,
+                            initial_xyzs=INIT_XYZS,
+                            initial_rpys=INIT_RPYS,
+                            freq=simulation_freq_hz,
+                            aggregate_phy_steps=AGGR_PHY_STEPS,
+                            gui=gui,
+                            physics=physics,
                             record=record_video
-                            )
+                        )
     logger = Logger(logging_freq_hz=int(env.SIM_FREQ/env.AGGR_PHY_STEPS),
                     num_drones=1,
                     output_folder=output_folder,
@@ -157,10 +196,9 @@ def run(env_id=DEFAULT_ENV,
     obs = env.reset()
     start = time.time()
     for i in range(30000*env.SIM_FREQ):
+        
         if not rllib and algo == 'ppo_sb3':
-            action, _states = model.predict(obs,
-                                            deterministic=True
-                                            )
+            action, _states = model.predict(obs, deterministic=True)
         elif algo == 'ppo_v2':
             action = policy(obs).detach().numpy()
         
@@ -173,11 +211,29 @@ def run(env_id=DEFAULT_ENV,
         if i%env.SIM_FREQ == 0:
             env.render()
             print(done)
-        sync(i, start, env.TIMESTEP)
+
+            if vision:
+                for j in range(num_drones):
+                    print(obs[str(j)]["rgb"].shape, np.average(obs[str(j)]["rgb"]),
+                          obs[str(j)]["dep"].shape, np.average(obs[str(j)]["dep"]),
+                          obs[str(j)]["seg"].shape, np.average(obs[str(j)]["seg"])
+                          )
+        
+        #### Sync the simulation ###################################
+        if gui:
+            sync(i, start, env.TIMESTEP)
+        
         if done:
             obs = env.reset()
+    
+    #### Close the environment #################################
     env.close()
 
+    #### Save the simulation results ###########################
+    logger.save()
+    logger.save_as_csv("pid") # Optional CSV save
+
+    #### Plot the simulation results ###########################
     if plot:
         logger.plot()
 
@@ -185,6 +241,16 @@ def run(env_id=DEFAULT_ENV,
 #######################################
 #######################################
 
+def make_env(env_id, seed=42):
+    env = gym.make(env_id)
+    env.seed(seed)
+    env.action_space.seed(seed)
+    env.observation_space.seed(seed)
+    return env
+
+#######################################
+#######################################
+
 
 if __name__ == "__main__":
     #### Define and parse (optional) arguments for the script ##
