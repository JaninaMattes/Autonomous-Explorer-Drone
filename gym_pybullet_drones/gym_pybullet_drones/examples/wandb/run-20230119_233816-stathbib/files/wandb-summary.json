{"train/timesteps": 10888, "train/mean policy loss": -0.12549300491809845, "train/mean value loss": 0.4528230130672455, "train/mean episode returns": -219.955144, "train/min episode returns": -342.682636, "train/max episode returns": -158.131904, "train/std episode returns": 53.060617, "train/mean episode runtime": 0.1068, "train/mean episode length": 207.9, "train/episodes": 4, "_timestamp": 1674167906.355139, "_runtime": 9.453964948654175, "_step": 4, "_wandb": {"runtime": 9}}