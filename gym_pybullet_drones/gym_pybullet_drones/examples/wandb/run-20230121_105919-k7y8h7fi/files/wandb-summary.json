{"train/timesteps": 233472, "train/mean policy loss": -0.03624200075864792, "train/mean value loss": 0.9973049759864807, "train/mean episode returns": -4.061869, "train/min episode returns": -4.062251, "train/max episode returns": -4.061493, "train/std episode returns": 0.000109, "train/mean episode runtime": 0.001035, "train/mean episode length": 1.0, "train/episodes": 113, "_timestamp": 1674299544.5136719, "_runtime": 4384.915321826935, "_step": 113}