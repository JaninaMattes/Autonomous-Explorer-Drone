{"train/timesteps": 3001115, "train/mean policy loss": -0.1224370002746582, "train/mean value loss": 0.028025999665260315, "train/mean episode returns": -48.804516, "train/min episode returns": -62.092179, "train/max episode returns": -47.901282, "train/std episode returns": 2.100773, "train/mean episode runtime": 0.012793, "train/mean episode length": 48.209302, "train/episodes": 1445, "_timestamp": 1674123472.3187, "_runtime": 1760.8656129837036, "_step": 1445, "_wandb": {"runtime": 1760}}