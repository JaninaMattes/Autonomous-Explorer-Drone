{"train/timesteps": 2079, "train/mean policy loss": -0.16652800142765045, "train/mean value loss": 0.9149770140647888, "train/mean episode returns": -213.566945, "train/min episode returns": -259.56452, "train/max episode returns": -165.077749, "train/std episode returns": 31.93451, "train/mean episode runtime": 0.074251, "train/mean episode length": 207.9, "train/episodes": 0, "_timestamp": 1674129937.024728, "_runtime": 6.4256181716918945, "_step": 0, "_wandb": {"runtime": 3}}