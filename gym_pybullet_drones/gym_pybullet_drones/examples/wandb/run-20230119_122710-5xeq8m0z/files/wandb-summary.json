{"train/timesteps": 3001115, "train/mean policy loss": -0.1224370002746582, "train/mean value loss": 0.028025999665260315, "train/mean episode returns": -48.804516, "train/min episode returns": -62.092179, "train/max episode returns": -47.901282, "train/std episode returns": 2.100773, "train/mean episode runtime": 0.017505, "train/mean episode length": 48.209302, "train/episodes": 1445, "_timestamp": 1674129685.7149088, "_runtime": 2055.236491918564, "_step": 1445, "_wandb": {"runtime": 2054}}