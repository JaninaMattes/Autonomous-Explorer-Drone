{"train/timesteps": 19290, "train/mean policy loss": -0.1674260050058365, "train/mean value loss": 0.09038499742746353, "train/mean episode returns": -160.410838, "train/min episode returns": -217.63054, "train/max episode returns": -133.460568, "train/std episode returns": 21.228609, "train/mean episode runtime": 0.087741, "train/mean episode length": 150.357143, "train/episodes": 8, "_timestamp": 1674167024.872772, "_runtime": 17.08525800704956, "_step": 8, "_wandb": {"runtime": 17}}