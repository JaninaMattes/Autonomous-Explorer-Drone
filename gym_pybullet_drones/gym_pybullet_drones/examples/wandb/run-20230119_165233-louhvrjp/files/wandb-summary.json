{"train/timesteps": 2048, "train/mean policy loss": 0.08043000102043152, "train/mean value loss": 0.5932729840278625, "train/mean episode returns": -9730.524153, "train/min episode returns": -12777.419885, "train/max episode returns": -6683.62842, "train/std episode returns": 3046.895733, "train/mean episode runtime": 0.339107, "train/mean episode length": 1024.0, "train/episodes": 0, "_timestamp": 1674143556.84566, "_runtime": 3.579993963241577, "_step": 0, "_wandb": {"runtime": 2}}