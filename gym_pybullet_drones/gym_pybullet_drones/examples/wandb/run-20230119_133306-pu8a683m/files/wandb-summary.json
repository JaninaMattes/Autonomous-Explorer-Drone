{"train/timesteps": 10679, "train/mean policy loss": -0.20395100116729736, "train/mean value loss": 0.3447670042514801, "train/mean episode returns": -232.056725, "train/min episode returns": -321.140806, "train/max episode returns": -188.80203, "train/std episode returns": 37.550352, "train/mean episode runtime": 0.070595, "train/mean episode length": 231.444444, "train/episodes": 4, "_timestamp": 1674131594.6124532, "_runtime": 7.796473264694214, "_step": 4, "_wandb": {"runtime": 7}}