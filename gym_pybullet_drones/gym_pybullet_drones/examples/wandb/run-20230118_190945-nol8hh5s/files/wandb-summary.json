{"train/timesteps": 497664, "train/mean policy loss": -0.10498200356960297, "train/mean value loss": 0.9968270063400269, "train/mean episode returns": -0.885388, "train/min episode returns": -0.885728, "train/max episode returns": -0.88509, "train/std episode returns": 8.9e-05, "train/mean episode runtime": 0.000529, "train/mean episode length": 1.0, "train/episodes": 242, "_timestamp": 1674075271.595009, "_runtime": 9886.375485181808, "_step": 242, "_wandb": {"runtime": 9891}}