{"train/timesteps": 29980, "train/mean policy loss": -0.1512250006198883, "train/mean value loss": 0.02052300050854683, "train/mean episode returns": -136.319141, "train/min episode returns": -165.142564, "train/max episode returns": -119.652462, "train/std episode returns": 12.841399, "train/mean episode runtime": 0.035085, "train/mean episode length": 128.0, "train/episodes": 13, "_timestamp": 1674167651.0712, "_runtime": 15.178460836410522, "_step": 13, "_wandb": {"runtime": 14}}