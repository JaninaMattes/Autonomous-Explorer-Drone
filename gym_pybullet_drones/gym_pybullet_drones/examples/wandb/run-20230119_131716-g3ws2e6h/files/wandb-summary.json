{"train/timesteps": 10679, "train/mean policy loss": -0.20395100116729736, "train/mean value loss": 0.3447670042514801, "train/mean episode returns": -232.056725, "train/min episode returns": -321.140806, "train/max episode returns": -188.80203, "train/std episode returns": 37.550352, "train/mean episode runtime": 0.08447, "train/mean episode length": 231.444444, "train/episodes": 4, "_timestamp": 1674130644.8555279, "_runtime": 8.804121971130371, "_step": 4, "_wandb": {"runtime": 7}}